# -*- coding: utf-8 -*-
"""Rede Neural.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v4DT334sh74uhESUHQnC6l6IJu6sD0My
"""

import pandas as pd
import warnings
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
warnings.filterwarnings('ignore')



df = pd.read_excel('base_tratada.xlsx')

df

#Preenchedo dados ausentes
df.interpolate(method='linear', inplace=True)

y = df['D0_FWD']
x = df.drop(df.columns[[2, 3, 4]], axis = 1)
rows = 20950
rows_treino = int(rows / 3)
x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.33, random_state=0)

from keras.models import Sequential
from keras.layers import Dense

# Crie a arquitetura da rede neural com os melhores hiperparâmetros
modelo = Sequential()
modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
modelo.add(Dense(units=1, activation="linear"))

# Compile o modelo
modelo.compile(loss='mse', optimizer='adam', metrics=['mae'])

# Treine a rede neural com os melhores hiperparâmetros
resultado = modelo.fit(x_treino, y_treino, epochs=400, batch_size=32, validation_data=(x_teste, y_teste))

import matplotlib.pyplot as plt

# Plotar gráfico histórico de treinamento
plt.plot(resultado.history['loss'])
plt.plot(resultado.history['val_loss'])
plt.title('Training History')
plt.ylabel('Cost function')
plt.xlabel('Training epochs')
plt.legend(['Training error', 'Test error'])

# Definir os limites do eixo y para limitar a escala
#plt.ylim(-1000, 500000)

plt.show()

# Fazer previsões no conjunto de teste
y_pred = modelo.predict(x_teste)

# Calcular métricas de desempenho
mse = mean_squared_error(y_teste, y_pred)
mae = mean_absolute_error(y_teste, y_pred)
r2 = r2_score(y_teste, y_pred)

# Imprimir métricas
print("MSE: ", mse)
print("MAE: ", mae)
print("R²: ", r2)

import numpy as np
import matplotlib.pyplot as plt

# Obtém os pesos do modelo
weights = modelo.get_weights()

# Calcula a importância das características com base nos pesos da primeira camada
first_layer_weights = weights[0]
feature_importance = np.abs(first_layer_weights).sum(axis=1)

# Crie uma lista de tuplas com o nome da característica e sua importância
feature_importance_list = list(zip(x.columns, feature_importance))

# Ordene a lista pelo valor de importância em ordem decrescente
feature_importance_list.sort(key=lambda x: x[1], reverse=True)

# Extraia os nomes das características ordenadas e suas importâncias correspondentes
sorted_feature_names, sorted_feature_importance = zip(*feature_importance_list)

# Plote o gráfico de importância das características ordenadas
plt.figure(figsize=(12, 6))
plt.bar(x=sorted_feature_names, height=sorted_feature_importance)
plt.title('Importância das Características (com base nos pesos)')
plt.xlabel('Características')
plt.ylabel('Importância')
plt.xticks(rotation=45)
plt.show()

"""Cross validation"""

from sklearn.model_selection import KFold
import numpy as np
import matplotlib.pyplot as plt

# Inicialize listas para armazenar as métricas de desempenho de cada dobra
mse_scores = []
mae_scores = []
r2_scores = []
rmse_scores = []

# Inicialize listas para armazenar métricas de desempenho em cada iteração
mse_per_iteration = []
mae_per_iteration = []

num_folds = 10  # Número de dobras para a validação cruzada
kf = KFold(n_splits=num_folds, shuffle=True, random_state=0)

for train_index, test_index in kf.split(x, y):
    x_train, x_test = x.iloc[train_index], x.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    # Treine e avalie o modelo como mencionado anteriormente
    modelo = Sequential()
    modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
    modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
    modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
    modelo.add(Dense(units=3, activation="relu", input_dim=x_treino.shape[1]))
    modelo.add(Dense(units=1, activation="linear"))
    modelo.compile(loss='mse', optimizer='adam', metrics=['mae'])
    resultado = modelo.fit(x_train, y_train, epochs=400, batch_size=32, validation_data=(x_test, y_test))

    # Calcule as métricas de desempenho
    y_pred = modelo.predict(x_test)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    # Calcule o RMSE (Root Mean Squared Error)
    rmse = np.sqrt(mse)

    # Armazene as métricas de desempenho em suas respectivas listas
    mse_scores.append(mse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    rmse_scores.append(rmse)

    # Armazene métricas de desempenho em cada iteração
    mse_per_iteration.append(mse)
    mae_per_iteration.append(mae)

# Calcule as métricas resumidas
avg_mse = np.mean(mse_scores)
avg_mae = np.mean(mae_scores)
avg_r2 = np.mean(r2_scores)
avg_rmse = np.mean(rmse_scores)

# Exiba ou armazene as métricas resumidas
print("MSE Médio:", avg_mse)
print("MAE Médio:", avg_mae)
print("R² Médio:", avg_r2)
print("RMSE Médio:", avg_rmse)

# Crie um gráfico que compare o MSE e o MAE a cada iteração
iterations = range(1, num_folds + 1)
plt.plot(iterations, mse_per_iteration, label='MSE', marker='o')
plt.plot(iterations, mae_per_iteration, label='MAE', marker='o')
plt.title('MSE vs. MAE em cada Iteração da Validação Cruzada')
plt.xlabel('Iteração da Validação Cruzada')
plt.ylabel('Erro')
plt.legend()
plt.show()

# Crie um gráfico de barras para comparar MSE e MAE para cada dobra
iterations = range(1, num_folds + 1)
width = 0.5  # Aumente a largura das barras
plt.bar(iterations, mse_scores, width, label='MSE')
plt.bar([i + width for i in iterations], mae_scores, width, label='MAE')
plt.xlabel('Dobras da Validação Cruzada')
plt.ylabel('Erro (log scale)')  # Use escala logarítmica no eixo y
plt.yscale('log')  # Escala logarítmica
plt.title('Comparação de MSE e MAE para Cada Dobra da Validação Cruzada')
plt.xticks([i + width/2 for i in iterations], iterations)

# Adicione rótulos de valores acima das barras, evitando a sobreposição
for i, (mse, mae) in enumerate(zip(mse_scores, mae_scores)):
    plt.text(iterations[i], mse, f'{mse:.1f}', ha='center', va='bottom', fontsize=7)
    plt.text(iterations[i] + width, mae, f'{mae:.1f}', ha='center', va='bottom', fontsize=7)

plt.legend(loc='best')
plt.show()