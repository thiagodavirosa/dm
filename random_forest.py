# -*- coding: utf-8 -*-
"""Random Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J38GL9eQ5b7y20rt-_ZWR8LlzxLQ5-_l
"""

!pip install graphviz

import pandas as pd
import warnings
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
warnings.filterwarnings('ignore')

df = pd.read_excel('base_tratada.xlsx')

#Preenchedo dados ausentes
df.interpolate(method='linear', inplace=True)

y = df['D0_FWD']
x = df.drop(df.columns[[2, 3, 4]], axis = 1)
rows = 20950
rows_treino = int(rows / 3)
x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3, random_state=0)
#x_treino, x_teste = x[0:rows_treino], x[rows_treino:]
#y_treino, y_teste = y[0:rows_treino], y[rows_treino:]

from sklearn.ensemble import RandomForestRegressor

#Define o número de estimadores:
estimator = 500

# Criar um modelo Random Forest
rf_model = RandomForestRegressor(n_estimators=estimator, random_state=0)  # Exemplo de hiperparâmetros

# Treinar o modelo com os dados de treinamento
rf_model.fit(x_treino, y_treino)  # x_treino são as variáveis de entrada, y_treino é a variável de saída

y_pred_rf = rf_model.predict(x_teste)  # x_teste são as variáveis de entrada do conjunto de teste
y_pred_rf_treino = rf_model.predict(x_treino)  # x_treino são as variáveis de entrada do conjunto de treinamento

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mse_rf = mean_squared_error(y_teste, y_pred_rf)
mae_rf = mean_absolute_error(y_teste, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)  # Calcule o RMSE a partir do MSE
r2_rf = r2_score(y_teste, y_pred_rf)

print("Desempenho do Random Forest:")
print("MSE: ", mse_rf)
print("MAE: ", mae_rf)
print("RMSE: ", rmse_rf)
print("R²: ", r2_rf)

import matplotlib.pyplot as plt

# Calcule os resíduos (diferença entre os valores reais e as previsões)
residuals = y_teste - y_pred_rf

# Crie um gráfico de resíduos
plt.scatter(y_pred_rf, residuals, color='blue', alpha=0.5)
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Previsões do Random Forest')
plt.ylabel('Resíduos')
plt.title('Gráfico de Resíduos: Resultados do Modelo Random Forest')
plt.show()

import matplotlib.pyplot as plt

# Crie um gráfico de dispersão para comparar previsões com valores reais nos conjuntos de treinamento e teste
plt.scatter(y_treino, y_pred_rf_treino, color='blue', label='Treinamento', alpha=0.5)
plt.scatter(y_teste, y_pred_rf, color='green', label='Teste', alpha=0.5)
plt.xlabel('Valores Reais')
plt.ylabel('Previsões do Random Forest')
plt.title('Comparação do Desempenho nos Conjuntos de Treinamento e Teste')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# MAE no conjunto de treinamento e no conjunto de teste
mae_treino = mean_absolute_error(y_treino, y_pred_rf_treino)
mae_teste = mean_absolute_error(y_teste, y_pred_rf)

# Crie uma lista com os valores de MAE e uma lista correspondente para indicar o conjunto (treinamento ou teste)
mae_values = [mae_treino, mae_teste]
conjunto = ['Treinamento', 'Teste']

# Crie um gráfico de barras para comparar o MAE nos dois conjuntos
plt.bar(conjunto, mae_values, color=['blue', 'green'])
plt.xlabel('Conjunto')
plt.ylabel('MAE')
plt.title('Comparação do MAE nos Conjuntos de Treinamento e Teste')

# Adicione os valores das barras
for i in range(len(conjunto)):
    plt.text(i, mae_values[i], f'{mae_values[i]:.3f}', ha='center', va='bottom')

plt.show()

from sklearn.tree import export_graphviz
# Exporte a primeira árvore da floresta (ou qualquer outra árvore)
tree = rf_model.estimators_[0]  # Aqui, estamos pegando a primeira árvore

# Exporte a árvore em formato DOT
export_graphviz(tree, out_file='tree.dot', feature_names=x_treino.columns, filled=True, rounded=True)

!dot -Tpng -Gdpi=2000 tree.dot -o tree.png
from IPython.display import Image
Image("tree.png")

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Defina o número de folds (k)
k = 10

# Inicialize listas para armazenar as métricas de desempenho
mse_scores = []
mae_scores = []
rmse_scores = []
r2_scores = []

# Inicialize o objeto KFold
kf = KFold(n_splits=k, shuffle=True, random_state=42)

# Itere sobre as folds
for train_index, test_index in kf.split(x_treino):  # x_treino são as suas variáveis de entrada de treinamento
    X_train, X_test = x_treino.iloc[train_index], x_treino.iloc[test_index]
    y_train, y_test = y_treino.iloc[train_index], y_treino.iloc[test_index]

    # Crie e treine seu modelo Random Forest no conjunto de treinamento
    rf_model = RandomForestRegressor(n_estimators=estimator, random_state=0)  # Exemplo de hiperparâmetros
    rf_model.fit(X_train, y_train)

    # Faça previsões no conjunto de teste
    y_pred = rf_model.predict(X_test)

    # Calcule as métricas de desempenho (MSE, MAE, RMSE e R²)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    # Adicione as métricas às listas de métricas
    mse_scores.append(mse)
    mae_scores.append(mae)
    rmse_scores.append(rmse)
    r2_scores.append(r2)

# Calcule as médias das métricas de desempenho
mean_mse = np.mean(mse_scores)
mean_mae = np.mean(mae_scores)
mean_rmse = np.mean(rmse_scores)
mean_r2 = np.mean(r2_scores)

print("Média do MSE:", mean_mse)
print("Média do MAE:", mean_mae)
print("Média do RMSE:", mean_rmse)
print("Média do R²:", mean_r2)

std_deviation = np.std(mse_scores)
std_deviation2 = np.std(mae_scores)
std_deviation3 = np.std(rmse_scores)
std_deviation4 = np.std(r2_scores)

print(f"Desvio Padrão das Pontuações MSE: {std_deviation:.3f}")
print(f"Desvio Padrão das Pontuações MAE: {std_deviation2:.3f}")
print(f"Desvio Padrão das Pontuações RMSE: {std_deviation3:.3f}")
print(f"Desvio Padrão das Pontuações R2: {std_deviation4:.3f}")

import matplotlib.pyplot as plt
import numpy as np

# Número de folds (k)
k = len(mse_scores)

# Índices das iterações
iterations = range(1, k + 1)

# Largura das barras
bar_width = 0.5

# Crie um gráfico de barras para o MSE e MAE juntos
plt.figure(figsize=(11, 5))
plt.bar(np.array(iterations) - bar_width/2, mse_scores, bar_width, color='blue', label='MSE', alpha=0.7)
plt.bar(np.array(iterations) + bar_width/2, mae_scores, bar_width, color='green', label='MAE', alpha=0.7)

plt.xlabel('Iteração da Validação Cruzada')
plt.ylabel('Pontuação (escala logarítmica)')
plt.yscale('log')  # Use escala logarítmica no eixo y
plt.title('Desempenho em cada Iteração')
plt.legend()

# Adicione rótulos com os valores nas barras com tamanho de fonte reduzido e posição otimizada
label_distance = 0.01  # Distância do rótulo para o topo da barra
label_positions = []

for i in range(len(iterations)):
    x_pos_mse = iterations[i] - bar_width / 2
    x_pos_mae = iterations[i] + bar_width / 2
    y_pos_mse = mse_scores[i] + label_distance
    y_pos_mae = mae_scores[i] + label_distance

    # Verifique se a posição do rótulo está muito próxima de outra barra
    if i > 0:
        while min(abs(y_pos_mse - label_positions[i - 1]), abs(y_pos_mae - label_positions[i - 1])) < 0.02:
            y_pos_mse += 0.02
            y_pos_mae += 0.02

    label_positions.append(y_pos_mse)
    plt.text(x_pos_mse, y_pos_mse, f'{mse_scores[i]:.3f}', ha='center', va='bottom', fontsize=8)
    plt.text(x_pos_mae, y_pos_mae, f'{mae_scores[i]:.3f}', ha='center', va='bottom', fontsize=8)

plt.show()

import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor

# Suponha que você já tenha criado e treinado seu modelo Random Forest
rf_model = RandomForestRegressor(n_estimators=estimator, random_state=0)
rf_model.fit(x_treino, y_treino)  # Substitua pelos seus dados reais

# Obtenha as importâncias das variáveis do modelo
importancias_variaveis = rf_model.feature_importances_

# Crie um DataFrame com as importâncias das variáveis e os nomes das variáveis
importancias_df = pd.DataFrame({'Variável': x_treino.columns, 'Importância': importancias_variaveis})

# Ordene o DataFrame por importância em ordem decrescente
importancias_df = importancias_df.sort_values(by='Importância', ascending=False)

# Crie um gráfico de barras para mostrar as importâncias
plt.figure(figsize=(10, 6))
plt.barh(importancias_df['Variável'], importancias_df['Importância'], color='skyblue')
plt.xlabel('Importância das Variáveis')
plt.ylabel('Variável')
plt.title('Importância das Variáveis na Random Forest')
plt.show()

"""Gradient Boosting para o seu conjunto de dados:"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Dividir o conjunto de dados em treinamento e teste
#X_treino, X_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.3, random_state=0)

# Inicializar o modelo Gradient Boosting
gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)

# Treinar o modelo com os dados de treinamento
gb_model.fit(x_treino, y_treino)

# Fazer previsões
y_pred_gb = gb_model.predict(x_teste)

# Avaliar o desempenho do modelo
mse_gb = mean_squared_error(y_teste, y_pred_gb)
mae_gb = mean_absolute_error(y_teste, y_pred_gb)
r2_gb = r2_score(y_teste, y_pred_gb)

print("Desempenho do Gradient Boosting:")
print("MSE: ", mse_gb)
print("MAE: ", mae_gb)
print("R²: ", r2_gb)

import matplotlib.pyplot as plt

# Gráfico de dispersão para o conjunto de treinamento
plt.figure(figsize=(12, 6))
plt.scatter(y_treino, gb_model.predict(x_treino), color='blue', label='Treinamento', alpha=0.5)
plt.scatter(y_teste, y_pred_gb, color='green', label='Teste', alpha=0.5)
plt.xlabel('Valores Reais')
plt.ylabel('Previsões')
plt.title('Gráfico de Dispersão - Previsões vs. Valores Reais')
plt.legend()
plt.show()

import matplotlib.pyplot as plt

# Calcular o MAE nos conjuntos de treinamento e teste
mae_treino = mean_absolute_error(y_treino, gb_model.predict(x_treino))
mae_teste = mean_absolute_error(y_teste, y_pred_gb)

# Criar listas com os valores de MAE e os rótulos dos conjuntos
mae_valores = [mae_treino, mae_teste]
conjuntos = ['Treinamento', 'Teste']

# Criar um gráfico de barras
plt.figure(figsize=(8, 6))
plt.bar(conjuntos, mae_valores, color=['blue', 'green'])
plt.xlabel('Conjunto de Dados')
plt.ylabel('MAE (Mean Absolute Error)')
plt.title('Comparação do MAE nos Conjuntos de Treinamento e Teste')
plt.text(0, mae_treino, f'{mae_treino:.2f}', ha='center', va='bottom')
plt.text(1, mae_teste, f'{mae_teste:.2f}', ha='center', va='bottom')
plt.show()

import matplotlib.pyplot as plt

# Obter as importâncias das variáveis
importancias_variaveis = gb_model.feature_importances_

# Obter nomes das variáveis independentes
nomes_variaveis = x.columns

# Criar um gráfico de barras para mostrar as importâncias
plt.figure(figsize=(12, 6))
plt.barh(nomes_variaveis, importancias_variaveis, color='blue')
plt.xlabel('Importância das Variáveis')
plt.ylabel('Variáveis Independentes')
plt.title('Importância das Variáveis no Modelo de Gradient Boosting')
plt.show()